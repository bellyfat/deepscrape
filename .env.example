# LLM Provider Configuration
# Options: openai, vllm, ollama, localai, litellm, custom
LLM_PROVIDER=openai

# OpenAI Configuration (when LLM_PROVIDER=openai)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o

# Local LLM Server Configuration (when using local providers)
# Base URL for the OpenAI-compatible API endpoint
LLM_BASE_URL=http://localhost:8000/v1
# API Key (can be any value for most local servers)
LLM_API_KEY=local-llm-key
# Model identifier (e.g., llama2 for Ollama, meta-llama/Llama-2-7b-chat-hf for vLLM)
LLM_MODEL=gpt-4o

# vLLM Specific Configuration
VLLM_API_KEY=
VLLM_TENSOR_PARALLEL_SIZE=1
VLLM_GPU_MEMORY_UTILIZATION=0.9
VLLM_MAX_MODEL_LEN=4096
VLLM_DTYPE=auto

# Ollama Specific Configuration
OLLAMA_MODELS_PATH=/root/.ollama/models
OLLAMA_KEEP_ALIVE=5m
OLLAMA_NUM_PARALLEL=4

# LocalAI Specific Configuration
LOCALAI_CONTEXT_SIZE=2048
LOCALAI_THREADS=4
LOCALAI_DEBUG=false
LOCALAI_PRELOAD_MODELS=
LOCALAI_BUILD_TYPE=cublas
LOCALAI_MODEL_URL=

# LiteLLM Specific Configuration
LITELLM_MASTER_KEY=sk-1234
LITELLM_DATABASE_URL=
LITELLM_LOG=INFO
LITELLM_TELEMETRY=false
# API Keys for various providers (when using LiteLLM)
ANTHROPIC_API_KEY=
GOOGLE_API_KEY=
COHERE_API_KEY=
REPLICATE_API_KEY=
HUGGINGFACE_API_KEY=
TOGETHERAI_API_KEY=
AZURE_API_KEY=
AZURE_API_BASE=
AZURE_API_VERSION=

# Custom LLM Provider Configuration
CUSTOM_LLM_IMAGE=your-llm-image:latest
CUSTOM_LLM_PORT=8000
CUSTOM_LLM_INTERNAL_PORT=8000
CUSTOM_LLM_COMMAND=
CUSTOM_LLM_AUTH_HEADER=
CUSTOM_LLM_SUPPORTS_JSON=false

# LLM Request Configuration
LLM_TIMEOUT=120000              # Request timeout in milliseconds
LLM_MAX_RETRIES=3              # Maximum retry attempts
LLM_TEMPERATURE=0.2            # Temperature for LLM responses
LLM_MAX_TOKENS=4000           # Maximum tokens for completion

# Extraction Settings
MAX_EXTRACTION_TOKENS=15000

# Scraper Configuration
MAX_TIMEOUT=60000
BLOCK_RESOURCES=true
BLOCK_ADS=true
USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36

# Redis Configuration - IMPORTANT: Use service name 'redis', not localhost
REDIS_HOST=redis
REDIS_PORT=6379

# Server Configuration
PORT=3000
NODE_ENV=development

# Caching Settings
CACHE_ENABLED=true
CACHE_TTL=3600          # Default cache TTL in seconds (1 hour)
CACHE_DIRECTORY=./cache # Directory to store cache files

# Crawl File Export
CRAWL_OUTPUT_DIR=./crawl-output # Directory to store crawled markdown files

# Logging Configuration
LOG_LEVEL=info
LOG_TO_FILE=true
LOG_DIRECTORY=./logs

# API Security
API_KEY=test-key

# Batch Processing Configuration
BATCH_PROCESSING_ENABLED=true
BATCH_OUTPUT_DIR=./batch-output    # Directory to store batch processing results
BATCH_CLEANUP_DAYS=7               # Days to keep batch data before cleanup
BATCH_MAX_CONCURRENT_JOBS=5        # Maximum concurrent batch operations